# Telegraf Configuration
#
# Telegraf is entirely plugin driven. All metrics are gathered from the
# declared inputs, and sent to the declared outputs.
#
# Plugins must be declared in here to be active.
# To deactivate a plugin, comment out the name and any variables.
#
# Use 'telegraf -config telegraf.conf -test' to see what metrics a config
# file would generate.
#
# Environment variables can be used anywhere in this config file, simply surround
# them with ${}. For strings the variable must be within quotes (ie, "${STR_VAR}"),
# for numbers and booleans they should be plain (ie, ${INT_VAR}, ${BOOL_VAR})

# Configuration for telegraf agent
[agent]
  ## Default data collection interval for all inputs
  interval = "10s"
  ## Rounds collection interval to 'interval'
  ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
  round_interval = false

  ## Telegraf will send metrics to outputs in batches of at most
  ## metric_batch_size metrics.
  ## This controls the size of writes that Telegraf sends to output plugins.
  metric_batch_size = 1000

  ## Maximum number of unwritten metrics per output.  Increasing this value
  ## allows for longer periods of output downtime without dropping metrics at the
  ## cost of higher maximum memory usage.
  metric_buffer_limit = 10000

  ## Collection jitter is used to jitter the collection by a random amount.
  ## Each plugin will sleep for a random time within jitter before collecting.
  ## This can be used to avoid many plugins querying things like sysfs at the
  ## same time, which can have a measurable effect on the system.
  collection_jitter = "20s"

  ## Collection offset is used to shift the collection by the given amount.
  ## This can be be used to avoid many plugins querying constraint devices
  ## at the same time by manually scheduling them in time.
  # collection_offset = "0s"

  ## Default flushing interval for all outputs. Maximum flush_interval will be
  ## flush_interval + flush_jitter
  flush_interval = "10s"
  ## Jitter the flush interval by a random amount. This is primarily to avoid
  ## large write spikes for users running a large number of telegraf instances.
  ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
  flush_jitter = "0s"

  ## Collected metrics are rounded to the precision specified. Precision is
  ## specified as an interval with an integer + unit (e.g. 0s, 10ms, 2us, 4s).
  ## Valid time units are "ns", "us" (or "Âµs"), "ms", "s".
  ##
  ## By default or when set to "0s", precision will be set to the same
  ## timestamp order as the collection interval, with the maximum being 1s:
  ##   ie, when interval = "10s", precision will be "1s"
  ##       when interval = "250ms", precision will be "1ms"
  ##
  ## Precision will NOT be used for service inputs. It is up to each individual
  ## service input to set the timestamp at the appropriate precision.
  precision = "0s"

  ## Log at debug level.
  # debug = false
  ## Log only error level messages.
  # quiet = false

  ## Log target controls the destination for logs and can be one of "file",
  ## "stderr" or, on Windows, "eventlog".  When set to "file", the output file
  ## is determined by the "logfile" setting.
  logtarget = "file"

  ## Name of the file to be logged to when using the "file" logtarget.  If set to
  ## the empty string then logs are written to stderr.
  logfile = "${VERBOSE_LOG_FILE_FULL_PATH:-}"

  ## The logfile will be rotated after the time interval specified.  When set
  ## to 0 no time based rotation is performed.  Logs are rotated only when
  ## written to, if there is no log activity rotation may be delayed.
  logfile_rotation_interval = "60s"

  ## The logfile will be rotated when it becomes larger than the specified
  ## size.  When set to 0 no size based rotation is performed.
  logfile_rotation_max_size = "4MB"

  ## Maximum number of rotated archives to keep, any older logs are deleted.
  ## If set to -1, no archives are removed.
  logfile_rotation_max_archives = 5

  ## Pick a timezone to use when logging or type 'local' for local time.
  ## Example: America/Chicago
  # log_with_timezone = ""

  ## Override default hostname, if empty use os.Hostname()
  hostname = ""
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = true

  ## Method of translating SNMP objects. Can be "netsnmp" (deprecated) which
  ## translates by calling external programs snmptranslate and snmptable,
  ## or "gosmi" which translates using the built-in gosmi library.
  # snmp_translator = "netsnmp"

  ## Name of the file to load the state of plugins from and store the state to.
  ## If uncommented and not empty, this file will be used to save the state of
  ## stateful plugins on termination of Telegraf. If the file exists on start,
  ## the state in the file will be restored for the plugins.
  # statefile = ""

[[inputs.outbound_connectivity]]
  interval = "${OUTBOUND_CONNECTIVITY_INTERVAL:-60s}"
  name_suffix = "${OUTBOUND_CONNECTIVITY_NAME_SUFFIX:-}"
  urls = "${OUTBOUND_CONNECTIVITY_URLS:-http://www.msftconnecttest.com/connecttest.txt}"
  timeout_in_milliseconds = ${OUTBOUND_CONNECTIVITY_TIMEOUT_IN_MILLISECONDS:-30000}

[[inputs.disk_io]]
  interval = "${DISK_IO_INTERVAL:-180s}"
  name_suffix = "${DISK_IO_NAME_SUFFIX:-}"
  mount_points = "${DISK_IO_MOUNT_POINTS:-}"
  ignore_file_system_list = "${DISK_IO_IGNORE_FS_LIST:-tmpfs,devtmpfs,devfs,iso9660,overlay,aufs,squashfs,autofs}"
  file_name = "${DISK_IO_FILENAME:-}"

[[inputs.simple]]
  interval = "${SIMPLE_INTERVAL:-10s}"
  name_suffix = "${SIMPLE_NAME_SUFFIX:-}"
  ok = ${SIMPLE_OK:-false}

[[inputs.az_storage_blob]]
    interval = "${AZ_STORAGE_BLOB_INTERVAL:-180s}"
    name_suffix = "${AZ_STORAGE_BLOB_NAME_SUFFIX:-}"
    storage_account_name = "${AZ_STORAGE_ACCOUNT_NAME:-}"
    container_name = "${AZ_STORAGE_CONTAINER_NAME:-}"
    blob_name = "${AZ_STORAGE_BLOB_NAME:-}"
    blob_domain_name = "${AZ_STORAGE_BLOB_DOMAIN_NAME:-blob.core.windows.net}"
    sas_token_base64 = "${AZ_STORAGE_SAS_TOKEN_BASE64:-}"
    use_managed_identity = ${AZ_STORAGE_USE_MANAGED_IDENTITY:-false}
    managed_identity_client_id = "${AZ_STORAGE_MANAGED_IDENTITY_CLIENT_ID:-}"

[[inputs.clockskew]]
    interval = "${CLOCK_SKEW_INTERVAL:-180s}"
    name_suffix = "${CLOCK_SKEW_NAME_SUFFIX:-}"
    ntp_server = "${CLOCK_SKEW_NTP_SERVER:-time.windows.com}"
    time_skew_threshold_in_seconds = ${CLOCK_SKEW_TIME_SKEW_THRESHOLD_IN_SECONDS:-5.0}

[[inputs.process]]
    interval = "${PROCESS_INTERVAL:-180s}"
    name_suffix = "${PROCESS_NAME_SUFFIX:-}"
    timeout = "${PROCESS_TIMEOUT:-10s}"

[[inputs.process_monitor]]
    interval = "${PROCESS_MONITOR_INTERVAL:-180s}"
    name_suffix = "${PROCESS_MONITOR_NAME_SUFFIX:-}"
    process_names = "${PROCESS_MONITOR_PROCESS_NAMES:-}"

[[inputs.test]]
    interval = "${TEST_INTERVAL:-1s}"
    name_suffix = "${TEST_NAME_SUFFIX:-}"
    exit_process = ${TEST_EXIT_PROCESS:-false}
    allocate_memory = ${TEST_ALLOCATE_MEMORY:-false}
    high_cpu = ${TEST_HIGH_CPU:-false}

[[inputs.dns]]
    interval = "${DNS_INTERVAL:-180s}"
    name_suffix = "${DNS_NAME_SUFFIX:-}"
    dns_names = "${DNS_NAMES:-www.msftconnecttest.com}"

[[inputs.imds]]
    interval = "${IMDS_INTERVAL:-180s}"
    name_suffix = "${IMDS_NAME_SUFFIX:-}"
    imds_endpoint = "${IMDS_ENDPOINT:-http://169.254.169.254/metadata/instance/compute}"
    timeout_in_seconds = ${IMDS_TIMEOUT_IN_SECONDS:-10}
    retry_interval_in_seconds = ${IMDS_RETRY_INTERVAL_IN_SEONDS:-3}
    query_Total_attempts = ${IMDS_QUERY_TOTAL_ATTEMPTS:-3}

[[inputs.tcp_stats]]
    interval = "${TCP_STATS_INTERVAL:-180s}"
    name_suffix = "${TCP_STATS_NAME_SUFFIX:-}"

[[inputs.process_cpu]]
    interval = "${PROCESS_CPU_INTERVAL:-180s}"
    name_suffix = "${PROCESS_CPU_NAME_SUFFIX:-}"

[[inputs.hardware_health_monitor]]
  interval = "${HARDWARE_HEALTH_MONITOR_INTERVAL:-180s}"
  name_override = "hardware_health_monitor"

[[aggregators.check_aggregator]]
    period = "${CHECK_AGGREGATION_INTERVAL:-300s}"
    drop_original = true
    [aggregators.check_aggregator.tagpass]
      EventLevel = ["Check"]

[[aggregators.metric_aggregator]]
    period = "${METRIC_AGGREGATION_INTERVAL:-300s}"
    drop_original = true
    [aggregators.metric_aggregator.tagpass]
      EventLevel = ["Metric"]

[[aggregators.eventlog_aggregator]]
    period = "${EVENTLOG_AGGREGATION_INTERVAL:-300s}"
    drop_original = true
    max_allowed_count =  ${EVENTLOG_AGGREGATION_MAX_ALLOWED_COUNT:-3}
    [aggregators.eventlog_aggregator.tagpass]
      EventLevel = ["EventLog"]

[[processors.event_processor]]
    period = "${EVENT_PROCESSOR_INTERVAL:-300s}"
    namepass = ["hardware_health_monitor"]
    [processors.event_processor.tagdrop]
      EventLevel = ["EventLog"]  # Telegraf processor processes signals sent from both inputs and aggregators. To prevent signals from feeding into the processor again after aggregation, excluding signals with tag EventLevel=EventLog as the processor adds this tag after processing.

# Send telegraf metrics to file(s)
[[outputs.file]]
  flush_interval = "30s"
  ## Files to write to, "stdout" is a specially handled file.
  folder = "${SIGNAL_FOLDER:-stdout}"

  ## Use batch serialization format instead of line based delimiting.  The
  ## batch format allows for the production of non line based output formats and
  ## may more efficiently encode and write metrics.
  use_batch_format = false

  ## The file will be rotated after the time interval specified.  When set
  ## to 0 no time based rotation is performed.
  rotation_interval = "10s"

  ## max number of files that can be present in the folder, if exceeded new files will not be written
  rotation_max_file_count = 1000

  ## The logfile will be rotated when it becomes larger than the specified
  ## size.  When set to 0 no size based rotation is performed.
  # rotation_max_size = "0MB"

  ## Data format to output.
  ## Each data format has its own unique set of configuration options, read
  ## more about them here:
  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md
  data_format = "json"
  json_timestamp_format = "2006-01-02T15:04:05Z07:00"
  json_nested_fields_include = ["RuntimeParameters", "Errors", "Stats", "Contents"]
  json_transformation = '''
    $merge([{"Timestamp": timestamp, "Message": $string( $merge([{"Name": name}, fields]) )}, tags])
  '''
[[outputs.file]]
  flush_interval = "30s"
  ## this output will be enabled if this variable is set otherwise it is a no-op
  ## it specifies and additional location to write the events to for troubleshooting
  folder = "${ADDITIONAL_SIGNAL_FOLDER_FOR_TROUBLESHOOTING:-}"

  ## Use batch serialization format instead of line based delimiting.  The
  ## batch format allows for the production of non line based output formats and
  ## may more efficiently encode and write metrics.
  use_batch_format = false

  ## The file will be rotated after the time interval specified.  When set
  ## to 0 no time based rotation is performed.
  rotation_interval = "10s"

  ## max number of files that can be present in the folder, if exceeded new files will not be written
  rotation_max_file_count = 1000

  ## The logfile will be rotated when it becomes larger than the specified
  ## size.  When set to 0 no size based rotation is performed.
  # rotation_max_size = "0MB"

  ## Data format to output.
  ## Each data format has its own unique set of configuration options, read
  ## more about them here:
  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md
  data_format = "json"
  json_timestamp_format = "2006-01-02T15:04:05Z07:00"
  json_nested_fields_include = ["RuntimeParameters", "Errors", "Stats", "Contents"]
  json_transformation = '''
    $merge([{"Timestamp": timestamp, "Message": $string( $merge([{"Name": name}, fields]) )}, tags])
  '''

